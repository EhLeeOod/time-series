{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cefd9059-42cc-47ad-bddd-7b2b3ee03513",
   "metadata": {},
   "source": [
    "# Seasonality in Modeling (SARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdee294-b24f-455e-9ec7-7b99586f713f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e006ca6b-b1c1-4fca-8e6d-6d17633684ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import statsmodels.tsa.api as tsa\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from pmdarima.arima.utils import ndiffs, nsdiffs\n",
    "\n",
    "# set random seed\n",
    "SEED = 321\n",
    "np.random.seed(SEED)\n",
    "\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "plt.rcParams['figure.figsize']=(12,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c31da-3aa8-46a4-b491-57a2e8d0a2e2",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76941f03-fcc8-4691-9819-2d50c039881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot forecast function\n",
    "def plot_forecast(ts_train, ts_test, forecast_df, n_train_lags=None, \n",
    "                  figsize=(10,4), title='Comparing Forecast vs. True Data'):\n",
    "    ### PLot training data, and forecast (with upper/,lower ci)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # setting the number of train lags to plot if not specified\n",
    "    if n_train_lags==None:\n",
    "        n_train_lags = len(ts_train)\n",
    "            \n",
    "    # Plotting Training  and test data\n",
    "    ts_train.iloc[-n_train_lags:].plot(ax=ax, label=\"train\")\n",
    "    ts_test.plot(label=\"test\", ax=ax)\n",
    "\n",
    "    # Plot forecast\n",
    "    forecast_df['mean'].plot(ax=ax, color='green', label=\"forecast\")\n",
    "\n",
    "    # Add the shaded confidence interval\n",
    "    ax.fill_between(forecast_df.index, \n",
    "                    forecast_df['mean_ci_lower'],\n",
    "                   forecast_df['mean_ci_upper'],\n",
    "                   color='green', alpha=0.3,  lw=2)\n",
    "\n",
    "    # set the title and add legend\n",
    "    ax.set_title(title)\n",
    "    ax.legend();\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e58f152-3214-4772-ab1b-99a9bb378568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression metrics function\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def regression_metrics_ts(ts_true, ts_pred, label=\"\", verbose=True, output_dict=False,):\n",
    "    # Get metrics\n",
    "    mae = mean_absolute_error(ts_true, ts_pred)\n",
    "    mse = mean_squared_error(ts_true, ts_pred)\n",
    "    rmse = mean_squared_error(ts_true, ts_pred, squared=False)\n",
    "    r_squared = r2_score(ts_true, ts_pred)\n",
    "    mae_perc = mean_absolute_percentage_error(ts_true, ts_pred) * 100\n",
    "\n",
    "    if verbose == True:\n",
    "        # Print Result with label\n",
    "        header = \"---\" * 20\n",
    "        print(header, f\"Regression Metrics: {label}\", header, sep=\"\\n\")\n",
    "        print(f\"- MAE = {mae:,.3f}\")\n",
    "        print(f\"- MSE = {mse:,.3f}\")\n",
    "        print(f\"- RMSE = {rmse:,.3f}\")\n",
    "        print(f\"- R^2 = {r_squared:,.3f}\")\n",
    "        print(f\"- MAPE = {mae_perc:,.2f}%\")\n",
    "\n",
    "    if output_dict == True:\n",
    "        metrics = {\n",
    "            \"Label\": label,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MAPE(%)\": mae_perc,\n",
    "        }\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46721620-86ff-48a4-b32a-cf925d0a4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad Fuller Test function\n",
    "def get_adfuller_results(ts, alpha=.05, label='adfuller', **kwargs): #kwargs for adfuller()\n",
    "    # Saving each output\n",
    "    (test_stat, pval, nlags, nobs, crit_vals_d, \n",
    "    icbest ) = tsa.adfuller(ts, **kwargs)\n",
    "    # Converting output to a dictionary with the interpretation of p\n",
    "    adfuller_results = {'Test Statistic': test_stat,\n",
    "                        \"# of Lags Used\":nlags, \n",
    "                       '# of Observations':nobs,\n",
    "                        'p-value': round(pval,6),\n",
    "                        'alpha': alpha,\n",
    "                       'sig/stationary?': pval < alpha}\n",
    "    return pd.DataFrame(adfuller_results, index =[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4645a2b8-6f84-45d7-a434-6a2a15db7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acf pacf plot function\n",
    "def plot_acf_pacf(ts, nlags=40, figsize=(10, 5), \n",
    "                  annotate_sig=False, alpha=.05,\n",
    "                 acf_kws={}, pacf_kws={},  \n",
    "                  annotate_seas=False, m = None,\n",
    "                 seas_color='black'):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, figsize=figsize)\n",
    "\n",
    "    \n",
    "    # Sig lags line style\n",
    "    sig_vline_kwargs = dict( ls=':', lw=1, zorder=0, color='red')\n",
    "\n",
    "    # ACF\n",
    "    tsa.graphics.plot_acf(ts, ax=axes[0], lags=nlags, **acf_kws)\n",
    "    \n",
    "    ## Annotating sig acf lags\n",
    "    if annotate_sig == True:\n",
    "        sig_acf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='ACF')\n",
    "        for lag in sig_acf_lags:\n",
    "            axes[0].axvline(lag,label='sig', **sig_vline_kwargs )\n",
    "\n",
    "    # PACF\n",
    "    tsa.graphics.plot_pacf(ts,ax=axes[1], lags=nlags, **pacf_kws)\n",
    "    \n",
    "    ## Annotating sig pacf lags\n",
    "    if annotate_sig == True:\n",
    "        ## ANNOTATING SIG LAGS\n",
    "        sig_pacf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='PACF')\n",
    "        for lag in sig_pacf_lags:\n",
    "            axes[1].axvline(lag, label='sig', **sig_vline_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### ANNOTATE SEASONS\n",
    "    if annotate_seas == True:\n",
    "        # Ensure m was defined\n",
    "        if m is None:\n",
    "            raise Exception(\"Must define value of m if annotate_seas=True.\")\n",
    "\n",
    "        ## Calculate number of complete seasons to annotate\n",
    "        n_seasons = nlags//m \n",
    "\n",
    "        # Seasonal Lines style\n",
    "        seas_vline_kwargs = dict( ls='--',lw=1, alpha=.7, color=seas_color, zorder=-1)\n",
    "        \n",
    "        ## for each season, add a line\n",
    "        for i in range(1, n_seasons+1):\n",
    "            axes[0].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "            axes[1].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f24cec-a55a-4044-859f-2af035e3dd37",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2556a0f-2a8f-4d96-99a1-e2387f3ecb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53712436-3ca3-4de2-b041-25ca0e180803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1958-03-29</th>\n",
       "      <td>316.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-04-05</th>\n",
       "      <td>317.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-04-12</th>\n",
       "      <td>317.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-04-19</th>\n",
       "      <td>317.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-04-26</th>\n",
       "      <td>316.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              co2\n",
       "1958-03-29  316.1\n",
       "1958-04-05  317.3\n",
       "1958-04-12  317.6\n",
       "1958-04-19  317.5\n",
       "1958-04-26  316.4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "co2_data = sm.datasets.co2.load_pandas()\n",
    "df = co2_data.data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d74eecf0-040e-4887-a653-c2fc85ad11fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute null values\n",
    "df['co2'] = df['co2'].interpolate()\n",
    "\n",
    "# check for null values\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31cb99-f2ba-4b4f-a3b6-fa42b13fed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resample Data to Monthly Using th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552994a-8008-4bec-9a8c-e1cbd3cec5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f3906-7b7e-4067-9f65-8ff0c878b009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86d109-feca-4859-b6ba-0c71997fc3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5a546-04a7-4172-bc3b-20f49ff24b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
